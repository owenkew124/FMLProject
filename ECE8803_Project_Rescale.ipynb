{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72c02be5",
   "metadata": {},
   "source": [
    "Set path as '/scratch/ECE8803_Project'. \n",
    "\n",
    "In this folder, you need to upload 'sam' data, label and samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aa79922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Path\n",
    "import os\n",
    "local_disk_root=os.environ[\"HOME\"] + '/scratch'\n",
    "root = local_disk_root+'/ECE8803_Project'\n",
    "os.chdir(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457bcf4b",
   "metadata": {},
   "source": [
    "Unpack 'Prompting results.zip' file. \n",
    "\n",
    "We are only going to use 'Dolphin Below', 'Cat', and 'Bus'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "537b32b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack Prompt Result (Run only once)\n",
    "\n",
    "# from zipfile import ZipFile\n",
    "# import shutil\n",
    "\n",
    "# zipobj = ZipFile('Prompting results.zip')\n",
    "# filenames = zipobj.namelist()[1:]  # all fileIds in the folder\n",
    "\n",
    "# with ZipFile('Prompting results.zip','r') as zipObject:\n",
    "#   for filename in filenames:\n",
    "#      zipObject.extract(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "633127f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Package\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from openpyxl import Workbook\n",
    "import os\n",
    "import random\n",
    "from IPython import get_ipython\n",
    "import time\n",
    "from PIL import Image\n",
    "from segment_anything import sam_model_registry, SamPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c281fec",
   "metadata": {},
   "source": [
    "Load SAM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "046f2274",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_checkpoint = 'sam_vit_h_4b8939.pth'\n",
    "model_type = \"vit_h\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13b6b98",
   "metadata": {},
   "source": [
    "Set User Parameters for Rescale Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd27daf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"Dolphin below\" # Dolphin below, Cat, Bus, Polyp, Stop Sign\n",
    "max_samples = 100\n",
    "num_student = 3\n",
    "rescale_ratio_set = [1.25, 1.5, 1.75, 2.0]\n",
    "mode_set = ['nearest', 'bilinear', 'bicubic', 'area']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724f55bd",
   "metadata": {},
   "source": [
    "Check Sample and Label exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32c2725b",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.load(dataset_name+\"_samples.npy\", allow_pickle=True)\n",
    "labels = np.load(dataset_name+\"_labels.npy\", allow_pickle=True)\n",
    "\n",
    "if not os.path.exists(dataset_name):\n",
    "    os.makedirs(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c31d4b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rescale the image and mask using Torch Interpolation\n",
    "def RescaleImage(image, size, mode='nearest'):\n",
    "    imageRawTensor = torch.from_numpy(image).permute(2, 0, 1).unsqueeze(0).float()\n",
    "    imageRescaleTensor = torch.nn.functional.interpolate(imageRawTensor, size=size, mode=mode)\n",
    "    imageRescale = imageRescaleTensor[0].permute(1, 2, 0).byte().numpy()\n",
    "    return imageRescale\n",
    "\n",
    "def RescaleMask(maskBool, size, mode='nearest'):\n",
    "    maskRawTensor = torch.from_numpy(maskBool).unsqueeze(0).unsqueeze(0).float()\n",
    "    maskRescaleTensor = torch.nn.functional.interpolate(maskRawTensor, size=size, mode=mode)\n",
    "    maskRescale = maskRescaleTensor[0,0].numpy()\n",
    "    maskRescaleBool = maskRescale > 0.5\n",
    "    return maskRescaleBool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec20006",
   "metadata": {},
   "source": [
    "Run and Test the Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9484cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio Student:  1\n",
      "Ratio Student:  2\n",
      "Ratio Student:  3\n"
     ]
    }
   ],
   "source": [
    "## start looping through samples:\n",
    "for student in np.arange(1,num_student+1):\n",
    "    print(\"Ratio Student: \", student) \n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "    ws['A1'] = 'Sample Number'\n",
    "    ws['B1'] = 'Scores'\n",
    "    ws['C1'] = 'Time Set'\n",
    "    ws['D1'] = 'Time Predict'\n",
    "    ws['E1'] = 'Rescale Ratio'\n",
    "    \n",
    "    num_files = 0\n",
    "    dir_path = \"Prompting results/\" + dataset_name + \"/st\" + str(student)\n",
    "    \n",
    "    # Count the number of samples\n",
    "    for path in os.listdir(dir_path + \"/scores/\"):\n",
    "        # check if current path is a file\n",
    "        if os.path.isfile(os.path.join(dir_path + \"/scores/\", path)):\n",
    "            num_files += 1      \n",
    "\n",
    "    # Test for Different Scale ratio\n",
    "    idx=0\n",
    "    for rescale_ratio in rescale_ratio_set:\n",
    "        mode = 'area'\n",
    "        c=0\n",
    "        while c < num_files and c < max_samples:\n",
    "            # Load Prompting result and use max score prompt\n",
    "            score_points = np.load(dir_path + \"/scores/\" + str(c) + \"score.npy\", allow_pickle=True)\n",
    "            if score_points.size == 0:\n",
    "                ws['A' + str(c + 2)] = str(c)\n",
    "                ws['B' + str(c + 2)] = str(0)  # samples name on excel\n",
    "                ws['C' + str(c + 2)] = str(0)\n",
    "                c += 1\n",
    "                continue\n",
    "            green_points = np.load(dir_path + \"/points/\" + str(c) + \"_green.npy\", allow_pickle=True)\n",
    "            if green_points.size == 0:\n",
    "                ws['A' + str(c + 2)] = str(c)\n",
    "                ws['B' + str(c + 2)] = str(0)  # samples name on excel\n",
    "                ws['C' + str(c + 2)] = str(0)\n",
    "                c += 1\n",
    "                continue\n",
    "            green_points = green_points[np.argmax(score_points)]\n",
    "            red_points = np.load(dir_path + \"/points/\" + str(c) + \"_red.npy\", allow_pickle=True)\n",
    "            if red_points.size == 0:\n",
    "                ws['A' + str(c + 2)] = str(c)\n",
    "                ws['B' + str(c + 2)] = str(0)  # samples name on excel\n",
    "                ws['C' + str(c + 2)] = str(0)\n",
    "                c += 1\n",
    "                continue\n",
    "            red_points = red_points[np.argmax(score_points)]\n",
    "            gp = []  # green points\n",
    "            rp = []  # red points\n",
    "\n",
    "            ## Load Image\n",
    "            image = names[c]  # samples c\n",
    "            if len(image.shape) == 2:\n",
    "                image = cv2.cvtColor((np.array(((image + 1) / 2) * 255, dtype='uint8')), cv2.COLOR_GRAY2RGB)\n",
    "            imshape = image.shape[0],image.shape[1]\n",
    "            if np.max(image) < 2:\n",
    "                image *= 255\n",
    "\n",
    "            ## Downsample the image\n",
    "            imreshape = (int(imshape[0] * rescale_ratio), int(imshape[1] * rescale_ratio))\n",
    "            imageDown = RescaleImage(image, imreshape, mode)\n",
    "\n",
    "            ## Load Label\n",
    "            label = labels[c]  # GT for sample c\n",
    "            label = label == 1\n",
    "            mask = 0\n",
    "\n",
    "            ## Set Downsampled Image\n",
    "            time_part1i = time.time()\n",
    "\n",
    "            predictor.set_image(imageDown)\n",
    "\n",
    "            time_part1 = time.time() - time_part1i\n",
    "\n",
    "            ## Concatenate Green and Red Prompts\n",
    "            x,y = 0,0\n",
    "            green = []\n",
    "            for g in green_points:\n",
    "                x = g[0] * rescale_ratio\n",
    "                y = g[1] * rescale_ratio\n",
    "                green.append((x, y))\n",
    "            red = []\n",
    "            for r in red_points:\n",
    "                x = r[0] * rescale_ratio\n",
    "                y = r[1] * rescale_ratio\n",
    "                red.append((x, y))\n",
    "\n",
    "            ## Predict Downsampled Image\n",
    "            score = 0.\n",
    "            time_part2 = 0.\n",
    "            if green and red:\n",
    "                input_point = np.concatenate((green, red))\n",
    "                input_label = np.concatenate(([1] * len(green), [0] * len(red)))\n",
    "\n",
    "                time_part2i = time.time()\n",
    "                masks, scores, logits = predictor.predict(\n",
    "                    point_coords=input_point,\n",
    "                    point_labels=input_label,\n",
    "                    multimask_output=True,\n",
    "                )\n",
    "                time_part2 = time.time() - time_part2i\n",
    "\n",
    "                ## Upsample the mask\n",
    "                maskDown = masks[0]\n",
    "                mask = RescaleMask(maskDown, imshape, mode)\n",
    "\n",
    "                ## Score calculation\n",
    "                intersection = (mask & label).sum()\n",
    "                union = (mask | label).sum()\n",
    "                if intersection == 0:\n",
    "                    score = 0\n",
    "                else:\n",
    "                    score = intersection / union\n",
    "\n",
    "            ws['A' + str(idx + 2)] = c+1\n",
    "            ws['B' + str(idx + 2)] = score\n",
    "            ws['C' + str(idx + 2)] = time_part1\n",
    "            ws['D' + str(idx + 2)] = time_part2\n",
    "            ws['E' + str(idx + 2)] = rescale_ratio\n",
    "            c += 1\n",
    "            idx += 1\n",
    "            \n",
    "    wb.save(os.path.join(dataset_name, dataset_name + '_st' + str(student) + '_upscale.xlsx'))\n",
    "    \n",
    "\n",
    "## start looping through samples:\n",
    "for student in np.arange(1,num_student+1):\n",
    "    print(\"Mode Student: \", student) \n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "    ws['A1'] = 'Sample Number'\n",
    "    ws['B1'] = 'Scores'\n",
    "    ws['C1'] = 'Time Set'\n",
    "    ws['D1'] = 'Time Predict'\n",
    "    ws['E1'] = 'Mode'\n",
    "    \n",
    "    num_files = 0\n",
    "    dir_path = \"Prompting results/\" + dataset_name + \"/st\" + str(student)\n",
    "    \n",
    "    # Count the number of samples\n",
    "    for path in os.listdir(dir_path + \"/scores/\"):\n",
    "        # check if current path is a file\n",
    "        if os.path.isfile(os.path.join(dir_path + \"/scores/\", path)):\n",
    "            num_files += 1      \n",
    "\n",
    "    # Test for Different Scale ratio\n",
    "    idx=0\n",
    "    for mode in mode_set:\n",
    "        rescale_ratio = 2.0\n",
    "        c=0\n",
    "        while c < num_files and c < max_samples:\n",
    "            # Load Prompting result and use max score prompt\n",
    "            score_points = np.load(dir_path + \"/scores/\" + str(c) + \"score.npy\", allow_pickle=True)\n",
    "            if score_points.size == 0:\n",
    "                ws['A' + str(c + 2)] = str(c)\n",
    "                ws['B' + str(c + 2)] = str(0)  # samples name on excel\n",
    "                ws['C' + str(c + 2)] = str(0)\n",
    "                c += 1\n",
    "                continue\n",
    "            green_points = np.load(dir_path + \"/points/\" + str(c) + \"_green.npy\", allow_pickle=True)\n",
    "            if green_points.size == 0:\n",
    "                ws['A' + str(c + 2)] = str(c)\n",
    "                ws['B' + str(c + 2)] = str(0)  # samples name on excel\n",
    "                ws['C' + str(c + 2)] = str(0)\n",
    "                c += 1\n",
    "                continue\n",
    "            green_points = green_points[np.argmax(score_points)]\n",
    "            red_points = np.load(dir_path + \"/points/\" + str(c) + \"_red.npy\", allow_pickle=True)\n",
    "            if red_points.size == 0:\n",
    "                ws['A' + str(c + 2)] = str(c)\n",
    "                ws['B' + str(c + 2)] = str(0)  # samples name on excel\n",
    "                ws['C' + str(c + 2)] = str(0)\n",
    "                c += 1\n",
    "                continue\n",
    "            red_points = red_points[np.argmax(score_points)]\n",
    "            gp = []  # green points\n",
    "            rp = []  # red points\n",
    "\n",
    "            ## Load Image\n",
    "            image = names[c]  # samples c\n",
    "            if len(image.shape) == 2:\n",
    "                image = cv2.cvtColor((np.array(((image + 1) / 2) * 255, dtype='uint8')), cv2.COLOR_GRAY2RGB)\n",
    "            imshape = image.shape[0],image.shape[1]\n",
    "            if np.max(image) < 2:\n",
    "                image *= 255\n",
    "\n",
    "            ## Downsample the image\n",
    "            imreshape = (int(imshape[0] * rescale_ratio), int(imshape[1] * rescale_ratio))\n",
    "            imageDown = RescaleImage(image, imreshape, mode)\n",
    "\n",
    "            ## Load Label\n",
    "            label = labels[c]  # GT for sample c\n",
    "            label = label == 1\n",
    "            mask = 0\n",
    "\n",
    "            ## Set Downsampled Image\n",
    "            time_part1i = time.time()\n",
    "\n",
    "            predictor.set_image(imageDown)\n",
    "\n",
    "            time_part1 = time.time() - time_part1i\n",
    "\n",
    "            ## Concatenate Green and Red Prompts\n",
    "            x,y = 0,0\n",
    "            green = []\n",
    "            for g in green_points:\n",
    "                x = g[0] * rescale_ratio\n",
    "                y = g[1] * rescale_ratio\n",
    "                green.append((x, y))\n",
    "            red = []\n",
    "            for r in red_points:\n",
    "                x = r[0] * rescale_ratio\n",
    "                y = r[1] * rescale_ratio\n",
    "                red.append((x, y))\n",
    "\n",
    "            ## Predict Downsampled Image\n",
    "            score = 0.\n",
    "            time_part2 = 0.\n",
    "            if green and red:\n",
    "                input_point = np.concatenate((green, red))\n",
    "                input_label = np.concatenate(([1] * len(green), [0] * len(red)))\n",
    "\n",
    "                time_part2i = time.time()\n",
    "                masks, scores, logits = predictor.predict(\n",
    "                    point_coords=input_point,\n",
    "                    point_labels=input_label,\n",
    "                    multimask_output=True,\n",
    "                )\n",
    "                time_part2 = time.time() - time_part2i\n",
    "\n",
    "                ## Upsample the mask\n",
    "                maskDown = masks[0]\n",
    "                mask = RescaleMask(maskDown, imshape, mode)\n",
    "\n",
    "                ## Score calculation\n",
    "                intersection = (mask & label).sum()\n",
    "                union = (mask | label).sum()\n",
    "                if intersection == 0:\n",
    "                    score = 0\n",
    "                else:\n",
    "                    score = intersection / union\n",
    "\n",
    "            ws['A' + str(idx + 2)] = c+1\n",
    "            ws['B' + str(idx + 2)] = score\n",
    "            ws['C' + str(idx + 2)] = time_part1\n",
    "            ws['D' + str(idx + 2)] = time_part2\n",
    "            ws['E' + str(idx + 2)] = mode\n",
    "            c += 1\n",
    "            idx += 1\n",
    "            \n",
    "    wb.save(os.path.join(dataset_name, dataset_name + '_st' + str(student) + '_mode_up.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f667d3a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-ECE8803]",
   "language": "python",
   "name": "conda-env-.conda-ECE8803-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
