{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72c02be5",
   "metadata": {},
   "source": [
    "Set path as '/scratch/ECE8803_Project'. \n",
    "\n",
    "In this folder, you need to upload 'sam' data, label and samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1aa79922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Path\n",
    "import os\n",
    "local_disk_root=os.environ[\"HOME\"] + '/scratch'\n",
    "root = local_disk_root+'/ECE8803_Project'\n",
    "os.chdir(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457bcf4b",
   "metadata": {},
   "source": [
    "Unpack 'Prompting results.zip' file. \n",
    "\n",
    "We are only going to use 'Dolphin Below', 'Cat', and 'Bus'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "537b32b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack Prompt Result (Run only once)\n",
    "\n",
    "# from zipfile import ZipFile\n",
    "# import shutil\n",
    "\n",
    "# zipobj = ZipFile('Prompting results.zip')\n",
    "# filenames = zipobj.namelist()[1:]  # all fileIds in the folder\n",
    "\n",
    "# with ZipFile('Prompting results.zip','r') as zipObject:\n",
    "#   for filename in filenames:\n",
    "#      zipObject.extract(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "633127f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Package\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from openpyxl import Workbook\n",
    "import os\n",
    "import random\n",
    "from IPython import get_ipython\n",
    "import time\n",
    "from PIL import Image\n",
    "from segment_anything import sam_model_registry, SamPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c281fec",
   "metadata": {},
   "source": [
    "Load SAM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "046f2274",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_checkpoint = 'sam_vit_h_4b8939.pth'\n",
    "model_type = \"vit_h\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13b6b98",
   "metadata": {},
   "source": [
    "Set User Parameters for Rescale Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd27daf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"Dolphin below\" # Dolphin below, Cat, Bus, Polyp, Stop sign\n",
    "max_samples = 100\n",
    "num_student = 3\n",
    "blur_ratio_set = [3, 7, 11]\n",
    "sharpen_ratio_set =  np.array([[[0,-1,0], [-1,5,-1], [-1,-1,-1]], [[-1,-1,-1], [-1,9,-1], [-1,-1,-1]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724f55bd",
   "metadata": {},
   "source": [
    "Check Sample and Label exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32c2725b",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.load(dataset_name+\"_samples.npy\", allow_pickle=True)\n",
    "labels = np.load(dataset_name+\"_labels.npy\", allow_pickle=True)\n",
    "\n",
    "if not os.path.exists(dataset_name):\n",
    "    os.makedirs(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec20006",
   "metadata": {},
   "source": [
    "Run and Test the Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9484cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blur Student:  1\n"
     ]
    }
   ],
   "source": [
    "## start looping through samples:\n",
    "for student in np.arange(1,num_student+1):\n",
    "    print(\"Blur Student: \", student) \n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "    ws['A1'] = 'Sample Number'\n",
    "    ws['B1'] = 'Scores'\n",
    "    ws['C1'] = 'Time Set'\n",
    "    ws['D1'] = 'Time Predict'\n",
    "    ws['E1'] = 'Blur Ratio'\n",
    "    \n",
    "    num_files = 0\n",
    "    dir_path = \"Prompting results/\" + dataset_name + \"/st\" + str(student)\n",
    "    \n",
    "    # Count the number of samples\n",
    "    for path in os.listdir(dir_path + \"/scores/\"):\n",
    "        # check if current path is a file\n",
    "        if os.path.isfile(os.path.join(dir_path + \"/scores/\", path)):\n",
    "            num_files += 1      \n",
    "\n",
    "    # Test for Different Scale ratio\n",
    "    idx=0\n",
    "    for blur_ratio in blur_ratio_set:\n",
    "        c=0\n",
    "        while c < num_files and c < max_samples:\n",
    "            # Load Prompting result and use max score prompt\n",
    "            score_points = np.load(dir_path + \"/scores/\" + str(c) + \"score.npy\", allow_pickle=True)\n",
    "            if score_points.size == 0:\n",
    "                ws['A' + str(c + 2)] = str(c)\n",
    "                ws['B' + str(c + 2)] = str(0)  # samples name on excel\n",
    "                ws['C' + str(c + 2)] = str(0)\n",
    "                c += 1\n",
    "                continue\n",
    "            green_points = np.load(dir_path + \"/points/\" + str(c) + \"_green.npy\", allow_pickle=True)\n",
    "            if green_points.size == 0:\n",
    "                ws['A' + str(c + 2)] = str(c)\n",
    "                ws['B' + str(c + 2)] = str(0)  # samples name on excel\n",
    "                ws['C' + str(c + 2)] = str(0)\n",
    "                c += 1\n",
    "                continue\n",
    "            green_points = green_points[np.argmax(score_points)]\n",
    "            red_points = np.load(dir_path + \"/points/\" + str(c) + \"_red.npy\", allow_pickle=True)\n",
    "            if red_points.size == 0:\n",
    "                ws['A' + str(c + 2)] = str(c)\n",
    "                ws['B' + str(c + 2)] = str(0)  # samples name on excel\n",
    "                ws['C' + str(c + 2)] = str(0)\n",
    "                c += 1\n",
    "                continue\n",
    "            red_points = red_points[np.argmax(score_points)]\n",
    "            gp = []  # green points\n",
    "            rp = []  # red points\n",
    "\n",
    "            ## Load Image\n",
    "            image = names[c]  # samples c\n",
    "            if len(image.shape) == 2:\n",
    "                image = cv2.cvtColor((np.array(((image + 1) / 2) * 255, dtype='uint8')), cv2.COLOR_GRAY2RGB)\n",
    "            imshape = image.shape[0],image.shape[1]\n",
    "            if np.max(image) < 2:\n",
    "                image = np.array(((image + 1) / 2) * 255, dtype='uint8')\n",
    "\n",
    "            ## Blur the image\n",
    "            imageBlur = cv2.GaussianBlur(image,(blur_ratio,blur_ratio),0)\n",
    "\n",
    "            ## Load Label\n",
    "            label = labels[c]  # GT for sample c\n",
    "            label = label == 1\n",
    "            mask = 0\n",
    "\n",
    "            ## Set Downsampled Image\n",
    "            time_part1i = time.time()\n",
    "\n",
    "            predictor.set_image(imageBlur)\n",
    "\n",
    "            time_part1 = time.time() - time_part1i\n",
    "\n",
    "            ## Concatenate Green and Red Prompts\n",
    "            x,y = 0,0\n",
    "            green = []\n",
    "            for g in green_points:\n",
    "                x = g[0]\n",
    "                y = g[1]\n",
    "                green.append((x, y))\n",
    "            red = []\n",
    "            for r in red_points:\n",
    "                x = r[0]\n",
    "                y = r[1]\n",
    "                red.append((x, y))\n",
    "\n",
    "            ## Predict Blurred Image\n",
    "            score = 0.\n",
    "            time_part2 = 0.\n",
    "            if green and red:\n",
    "                input_point = np.concatenate((green, red))\n",
    "                input_label = np.concatenate(([1] * len(green), [0] * len(red)))\n",
    "\n",
    "                time_part2i = time.time()\n",
    "                masks, scores, logits = predictor.predict(\n",
    "                    point_coords=input_point,\n",
    "                    point_labels=input_label,\n",
    "                    multimask_output=True,\n",
    "                )\n",
    "                time_part2 = time.time() - time_part2i\n",
    "\n",
    "                ## Score calculation\n",
    "                mask = masks[0]\n",
    "                intersection = (mask & label).sum()\n",
    "                union = (mask | label).sum()\n",
    "                if intersection == 0:\n",
    "                    score = 0\n",
    "                else:\n",
    "                    score = intersection / union\n",
    "\n",
    "            ws['A' + str(idx + 2)] = c+1\n",
    "            ws['B' + str(idx + 2)] = score\n",
    "            ws['C' + str(idx + 2)] = time_part1\n",
    "            ws['D' + str(idx + 2)] = time_part2\n",
    "            ws['E' + str(idx + 2)] = blur_ratio\n",
    "            c += 1\n",
    "            idx += 1\n",
    "            \n",
    "    wb.save(os.path.join(dataset_name, dataset_name + '_st' + str(student) + '_blur.xlsx'))\n",
    "    \n",
    "\n",
    "## start looping through samples:\n",
    "for student in np.arange(1,num_student+1):\n",
    "    print(\"Sharpen Student: \", student) \n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "    ws['A1'] = 'Sample Number'\n",
    "    ws['B1'] = 'Scores'\n",
    "    ws['C1'] = 'Time Set'\n",
    "    ws['D1'] = 'Time Predict'\n",
    "    ws['E1'] = 'Sharpness'\n",
    "    \n",
    "    num_files = 0\n",
    "    dir_path = \"Prompting results/\" + dataset_name + \"/st\" + str(student)\n",
    "    \n",
    "    # Count the number of samples\n",
    "    for path in os.listdir(dir_path + \"/scores/\"):\n",
    "        # check if current path is a file\n",
    "        if os.path.isfile(os.path.join(dir_path + \"/scores/\", path)):\n",
    "            num_files += 1      \n",
    "\n",
    "    # Test for Different Scale ratio\n",
    "    idx=0\n",
    "    for sharpener in sharpen_ratio_set:\n",
    "        c=0\n",
    "        while c < num_files and c < max_samples:\n",
    "            # Load Prompting result and use max score prompt\n",
    "            score_points = np.load(dir_path + \"/scores/\" + str(c) + \"score.npy\", allow_pickle=True)\n",
    "            if score_points.size == 0:\n",
    "                ws['A' + str(c + 2)] = str(c)\n",
    "                ws['B' + str(c + 2)] = str(0)  # samples name on excel\n",
    "                ws['C' + str(c + 2)] = str(0)\n",
    "                c += 1\n",
    "                continue\n",
    "            green_points = np.load(dir_path + \"/points/\" + str(c) + \"_green.npy\", allow_pickle=True)\n",
    "            if green_points.size == 0:\n",
    "                ws['A' + str(c + 2)] = str(c)\n",
    "                ws['B' + str(c + 2)] = str(0)  # samples name on excel\n",
    "                ws['C' + str(c + 2)] = str(0)\n",
    "                c += 1\n",
    "                continue\n",
    "            green_points = green_points[np.argmax(score_points)]\n",
    "            red_points = np.load(dir_path + \"/points/\" + str(c) + \"_red.npy\", allow_pickle=True)\n",
    "            if red_points.size == 0:\n",
    "                ws['A' + str(c + 2)] = str(c)\n",
    "                ws['B' + str(c + 2)] = str(0)  # samples name on excel\n",
    "                ws['C' + str(c + 2)] = str(0)\n",
    "                c += 1\n",
    "                continue\n",
    "            red_points = red_points[np.argmax(score_points)]\n",
    "            gp = []  # green points\n",
    "            rp = []  # red points\n",
    "\n",
    "            ## Load Image\n",
    "            image = names[c]  # samples c\n",
    "            if len(image.shape) == 2:\n",
    "                image = cv2.cvtColor((np.array(((image + 1) / 2) * 255, dtype='uint8')), cv2.COLOR_GRAY2RGB)\n",
    "            imshape = image.shape[0],image.shape[1]\n",
    "            if np.max(image) < 2:\n",
    "                image = np.array(((image + 1) / 2) * 255, dtype='uint8')\n",
    "\n",
    "            ## Sharpen the image\n",
    "            imageSharp = cv2.filter2D(image, -1, sharpener)\n",
    "\n",
    "            ## Load Label\n",
    "            label = labels[c]  # GT for sample c\n",
    "            label = label == 1\n",
    "            mask = 0\n",
    "\n",
    "            ## Set Downsampled Image\n",
    "            time_part1i = time.time()\n",
    "\n",
    "            predictor.set_image(imageSharp)\n",
    "\n",
    "            time_part1 = time.time() - time_part1i\n",
    "\n",
    "            ## Concatenate Green and Red Prompts\n",
    "            x,y = 0,0\n",
    "            green = []\n",
    "            for g in green_points:\n",
    "                x = g[0]\n",
    "                y = g[1]\n",
    "                green.append((x, y))\n",
    "            red = []\n",
    "            for r in red_points:\n",
    "                x = r[0]\n",
    "                y = r[1]\n",
    "                red.append((x, y))\n",
    "\n",
    "            ## Predict Sharpen Image\n",
    "            score = 0.\n",
    "            time_part2 = 0.\n",
    "            if green and red:\n",
    "                input_point = np.concatenate((green, red))\n",
    "                input_label = np.concatenate(([1] * len(green), [0] * len(red)))\n",
    "\n",
    "                time_part2i = time.time()\n",
    "                masks, scores, logits = predictor.predict(\n",
    "                    point_coords=input_point,\n",
    "                    point_labels=input_label,\n",
    "                    multimask_output=True,\n",
    "                )\n",
    "                time_part2 = time.time() - time_part2i\n",
    "\n",
    "                ## Score calculation\n",
    "                mask = masks[0]\n",
    "                intersection = (mask & label).sum()\n",
    "                union = (mask | label).sum()\n",
    "                if intersection == 0:\n",
    "                    score = 0\n",
    "                else:\n",
    "                    score = intersection / union\n",
    "\n",
    "            ws['A' + str(idx + 2)] = c+1\n",
    "            ws['B' + str(idx + 2)] = score\n",
    "            ws['C' + str(idx + 2)] = time_part1\n",
    "            ws['D' + str(idx + 2)] = time_part2\n",
    "            ws['E' + str(idx + 2)] = sharpener[1,1]\n",
    "            c += 1\n",
    "            idx += 1\n",
    "            \n",
    "    wb.save(os.path.join(dataset_name, dataset_name + '_st' + str(student) + '_sharpen.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f667d3a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-ECE8803]",
   "language": "python",
   "name": "conda-env-.conda-ECE8803-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
